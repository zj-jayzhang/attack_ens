{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec09074f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "from robustbench.data import get_preprocessing, load_clean_dataset\n",
    "from robustbench.model_zoo.enums import BenchmarkDataset, ThreatModel\n",
    "from robustbench.utils import clean_accuracy\n",
    "from pathlib import Path\n",
    "from typing import Callable, Optional, Sequence, Tuple, Union\n",
    "from autoattack import AutoAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "659bdb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(\n",
    "    model: Union[nn.Module, Sequence[nn.Module]],\n",
    "    n_examples: int = 10000,\n",
    "    dataset: Union[str, BenchmarkDataset] = BenchmarkDataset.cifar_10,\n",
    "    threat_model: Union[str, ThreatModel] = ThreatModel.Linf,\n",
    "    model_name: Optional[str] = None,\n",
    "    data_dir: str = \"./data\",\n",
    "    device: Optional[Union[torch.device, Sequence[torch.device]]] = None,\n",
    "    batch_size: int = 32,\n",
    "    eps: Optional[float] = None,\n",
    "    log_path: Optional[str] = None,\n",
    "\n",
    "    version='custom', #'rand', # 'rand' for models using stochasticity\n",
    "\n",
    "    preprocessing: Optional[Union[str, Callable]] = None,\n",
    "    aa_state_path: Optional[Path] = None,\n",
    "    image_path: Optional[str] = None,\n",
    "\n",
    "    ) -> Tuple[float, float]:\n",
    "    if isinstance(model, Sequence) or isinstance(device, Sequence):\n",
    "        # Multiple models evaluation in parallel not yet implemented\n",
    "        raise NotImplementedError\n",
    "\n",
    "    try:\n",
    "        if model.training:\n",
    "            warnings.warn(Warning(\"The given model is *not* in eval mode.\"))\n",
    "    except AttributeError:\n",
    "        warnings.warn(\n",
    "            Warning(\n",
    "                \"It is not possible to asses if the model is in eval mode\"))\n",
    "\n",
    "    dataset_: BenchmarkDataset = BenchmarkDataset(dataset)\n",
    "    threat_model_: ThreatModel = ThreatModel(threat_model)\n",
    "    model = model.cuda()\n",
    "\n",
    "    prepr = get_preprocessing(dataset_, threat_model_, model_name,\n",
    "                            preprocessing)\n",
    "\n",
    "    clean_x_test, clean_y_test = load_clean_dataset(dataset_, n_examples,\n",
    "                                                    data_dir, prepr)\n",
    "\n",
    "    clean_accs = []\n",
    "    for i in range(10):\n",
    "        accuracy = clean_accuracy(model,\n",
    "                                clean_x_test,\n",
    "                                clean_y_test,\n",
    "                                batch_size=batch_size,\n",
    "                                device=device)\n",
    "        clean_accs.append(accuracy)\n",
    "    print(f'With {len(clean_x_test)} clean examples, test for 10 times, clean accuracy: {np.mean(clean_accs):.2%}±{np.std(clean_accs):.2%}')\n",
    "\n",
    "    do_auto_attack = True\n",
    "    if do_auto_attack:\n",
    "        # AutoAttack\n",
    "        adversary = AutoAttack(\n",
    "                            model,  # at default, this will call aggreegated model\n",
    "                            norm=threat_model_.value,\n",
    "                            eps=eps,\n",
    "                            version=version,\n",
    "                            device=device,\n",
    "                            log_path=log_path,\n",
    "                            attacks_to_run=['apgd-ce', 'apgd-t'] if version == \"custom\" else [], #Stan's addition\n",
    "                            )\n",
    "        x_adv = adversary.run_standard_evaluation(\n",
    "                                                clean_x_test,\n",
    "                                                clean_y_test,\n",
    "                                                bs=batch_size,\n",
    "                                                state_path=aa_state_path)\n",
    "        \n",
    "        #calculate the robust accuracy for 10 times, then report the average accuracy and std\n",
    "        accs = []\n",
    "        for i in range(10):\n",
    "            adv_accuracy = clean_accuracy(\n",
    "                                        model,\n",
    "                                        x_adv,\n",
    "                                        clean_y_test,\n",
    "                                        batch_size=batch_size,\n",
    "                                        device=device)\n",
    "            accs.append(adv_accuracy)\n",
    "        print(f'After auto attack, with {len(clean_x_test)} clean examples,  test for 10 times, robust accuracy: {np.mean(accs):.2%}±{np.std(accs):.2%}')\n",
    "        print(\"===================================\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Skip AutoAttack\")\n",
    "    # note: load adversarial images generated by our attack\n",
    "    saved_adv_images = np.load(f\"{image_path}\")\n",
    "    saved_adv_images = torch.tensor(saved_adv_images).cuda()\n",
    "    accs = []\n",
    "    for i in range(10):\n",
    "        adv_accuracy = clean_accuracy(\n",
    "                                    model,\n",
    "                                    saved_adv_images[:len(clean_y_test)],\n",
    "                                    clean_y_test,\n",
    "                                    batch_size=batch_size,\n",
    "                                    device=device)\n",
    "        accs.append(adv_accuracy)\n",
    "    print(\"===================================\")\n",
    "    print(f'After our attack, with {len(clean_x_test)} clean examples,  test for 10 times, robust accuracy: {np.mean(accs):.2%}±{np.std(accs):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "249634c7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from helpers.utils import setup_seed\n",
    "setup_seed(1)\n",
    "\n",
    "#! test it on cifar100\n",
    "wrapped_combined_model = torch.load('/data/projects/ensem_adv/saved_ckpts/full_model.pth')\n",
    "data_dir = \"/local/home/jiezha/data/\"\n",
    "\n",
    "\n",
    "time_start = time.time()\n",
    "# benchmark(\n",
    "#         wrapped_combined_model.eval(),\n",
    "#         dataset=\"cifar100\",\n",
    "#         threat_model='Linf',\n",
    "#         device=torch.device(\"cuda\"),\n",
    "#         eps=8/255,\n",
    "#         n_examples=100,  # test on 100 examples\n",
    "#         version='rand',\n",
    "#         batch_size=32,\n",
    "#         data_dir=data_dir,\n",
    "#         image_path=\"saved/saved_adv_images_final_cifar100.npy\"\n",
    "#     )\n",
    "# time_end = time.time()\n",
    "# print(f\"Time cost:  {(time_end-time_start)/60} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1279d84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "With 100 clean examples, test for 10 times, clean accuracy: 86.60%±2.01%\n",
      "setting parameters for rand version\n",
      "using rand version including apgd-ce, apgd-dlr.\n",
      "initial accuracy: 83.00%\n",
      "apgd-ce - 1/3 - 17 out of 32 successfully perturbed\n",
      "apgd-ce - 2/3 - 13 out of 32 successfully perturbed\n",
      "apgd-ce - 3/3 - 7 out of 19 successfully perturbed\n",
      "robust accuracy after APGD-CE: 46.00% (total time 2705.6 s)\n",
      "apgd-dlr - 1/2 - 4 out of 32 successfully perturbed\n",
      "apgd-dlr - 2/2 - 1 out of 14 successfully perturbed\n",
      "robust accuracy after APGD-DLR: 41.00% (total time 4256.6 s)\n",
      "max Linf perturbation: 0.03137, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
      "robust accuracy: 41.00%\n",
      "After auto attack, with 100 clean examples,  test for 10 times, robust accuracy: 61.80%±2.32%\n",
      "===================================\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saved/saved_adv_images_final_cifar10.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m wrapped_combined_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/projects/ensem_adv/saved_ckpts/full_model_cifar10.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrapped_combined_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcifar10\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreat_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLinf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# test on 100 examples\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved/saved_adv_images_final_cifar10.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime cost:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time_end\u001b[38;5;241m-\u001b[39mtime_start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mins\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 86\u001b[0m, in \u001b[0;36mbenchmark\u001b[0;34m(model, n_examples, dataset, threat_model, model_name, data_dir, device, batch_size, eps, log_path, version, preprocessing, aa_state_path, image_path)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkip AutoAttack\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# note: load adversarial images generated by our attack\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m saved_adv_images \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mimage_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m saved_adv_images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(saved_adv_images)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     88\u001b[0m accs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/local/home/jiezha/micromamba/envs/clip/lib/python3.11/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved/saved_adv_images_final_cifar10.npy'"
     ]
    }
   ],
   "source": [
    "#! test it on cifar10\n",
    "\n",
    "wrapped_combined_model = torch.load('/data/projects/ensem_adv/saved_ckpts/full_model_cifar10.pth')\n",
    "\n",
    "time_start = time.time()\n",
    "benchmark(\n",
    "        wrapped_combined_model.eval(),\n",
    "        dataset=\"cifar10\",\n",
    "        threat_model='Linf',\n",
    "        device=torch.device(\"cuda\"),\n",
    "        eps=8/255,\n",
    "        n_examples=100,  # test on 100 examples\n",
    "        version='rand',\n",
    "        batch_size=32,\n",
    "        data_dir=data_dir,\n",
    "        image_path=\"saved/saved_adv_images_final_cifar10.npy\"\n",
    "    )\n",
    "time_end = time.time()\n",
    "print(f\"Time cost:  {(time_end-time_start)/60} mins\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
